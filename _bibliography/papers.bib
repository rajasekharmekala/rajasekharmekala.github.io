---
---

@string{aps = {American Physical Society,}}


@article{mekala2023echoprompt,
  abbr={NAACL},
  title={EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning},
  author={Rajasekhar Reddy Mekala and Yasaman Razeghi and Sameer Singh},
  abstract={Language models are achieving impressive performance on various tasks by aggressively adopting inference-time prompting techniques, such as zero-shot and few-shot prompting. In this work, we introduce EchoPrompt, a simple yet effective approach that prompts the model to rephrase its queries before answering them. EchoPrompt is adapted for both zero-shot and few-shot in-context learning with standard and chain-of-thought prompting. Experimental results show that EchoPrompt yields substantial improvements across all these settings for four families of causal language models. These improvements are observed across various numerical reasoning (e.g. GSM8K, SVAMP), reading comprehension (e.g. DROP), and logical reasoning (e.g. Coin Flipping) tasks. On average, EchoPrompt improves the Zero-shot-CoT performance of code-davinci-002 by 5% in numerical tasks and 13% in reading comprehension tasks. We investigate the factors contributing to EchoPrompt's effectiveness through ablation studies, which reveal that both the original query and the model-generated rephrased version are instrumental in its performance gains. Our empirical results indicate that EchoPrompt is an effective technique that enhances in-context learning performance. We recommend incorporating EchoPrompt into various baseline prompting strategies to achieve performance boosts.},
  year={2023},
  month={Oct},
  pdf={https://arxiv.org/pdf/2309.10687.pdf},
  dimensions={true},
  selected={true}
}

@article{razeghisnoopy,
  abbr={EMNLP},
  title={Snoopy: An Online Interface for Exploring the Effect of Pretraining Term Frequencies on Few-Shot LM Performance},
  author={Razeghi, Y. and Mekala, M. and Logan, R. and Gardner, M. and Singh, S.},
  abstract={Current evaluation schemes for large language models often fail to consider the impact of the overlap between pretraining corpus and test data on model performance statistics. Snoopy is an online interface that allows researchers to study this impact in few-shot learning settings. Our demo provides term frequency statistics for the Pile, which is an 800GB corpus, ac- companied by the precomputed performance of EleutherAI/GPT models on more than 20 NLP benchmarks, including numerical, common- sense reasoning, natural language understand- ing, and question-answering tasks. Snoopy al- lows a user to interactively align specific terms in test instances with their frequency in the Pile, enabling exploratory analysis of how term frequency is related to the accuracy of the mod- els, which are hard to discover through au- tomated means. A user can look at correla- tions over various model sizes and numbers of in-context examples and visualize the re- sult across multiple (potentially aggregated) datasets. Using Snoopy, we show that a re- searcher can quickly replicate prior analyses for numerical tasks, while simultaneously allowing for much more expansive exploration that was previously challenging. Snoopy is available at https://nlp.ics.uci.edu/snoopy.},
  year={2022},
  month={Oct},
  pdf={https://docs.google.com/document/d/15lGjtPNoiq4MQPUAV3lEqmsDOUfdhSUiGCk-wMefVt8/edit?usp=sharing},
  dimensions={true},
  selected={true}
}

@article{mumford2020sunpy,
  abbr={JOSS},
  title={SunPy: a python package for solar physics},
  author={Mumford, Stuart and Freij, Nabil and Christe, Steven and Ireland, Jack and Mayer, Florian and Hughitt, V and Shih, Albert and Ryan, Daniel and Liedtke, Simon and P{\'e}rez-Su{\'a}rez, David and others},
  journal={Journal of Open Source Software},
  volume={5},
  number={46},
  year={2020},
  publisher={The Open Journal},
  pdf={https://discovery.ucl.ac.uk/id/eprint/10092266/1/10.21105.joss.01832.pdf},
  selected={true}
}